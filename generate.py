import pandas as pd
from openai import AsyncOpenAI
from dotenv import load_dotenv
import os
import asyncio

load_dotenv()
AI_TOKEN = os.getenv('AI_TOKEN')

client = AsyncOpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=AI_TOKEN,
)

async def ai_generate_from_csv():
    # –ß–∏—Ç–∞–µ–º CSV —Ñ–∞–π–ª—ã
    df1 = pd.read_csv(r'reviews_com.logistic.sdek\reviews_1_stars.csv')
    df2 = pd.read_csv(r'reviews_com.logistic.sdek\reviews_5_stars.csv')
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
    csv1_text = df1.to_string(index=False)
    csv2_text = df2.to_string(index=False)
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ CSV
    prompt = f"""
–î–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Ñ–∞–π–ª–∞ —Å 1 –∑–≤–µ–∑–¥–æ–π:
{csv1_text}

–î–∞–Ω–Ω—ã–µ –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ —Ñ–∞–π–ª–∞ —Å 5 –∑–≤–µ–∑–¥–∞–º–∏:
{csv2_text}
"""
    
    models_to_try = [
        "deepseek/deepseek-r1:free",
        "microsoft/wizardlm-2-8x22b:free",
        "meta-llama/llama-3.1-8b-instruct:free",
        "qwen/qwen-2.5-32b-instruct:free"        
    ]
    
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
    max_retries = 2
    for model in models_to_try:
        for attempt in range(max_retries):
            try:
                print(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} —Å –º–æ–¥–µ–ª—å—é: {model}")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                if attempt > 0:
                    wait_time = 30  # 30 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–∞–º–∏
                    print(f"‚è≥ –ñ–¥–µ–º {wait_time} —Å–µ–∫—É–Ω–¥...")
                    await asyncio.sleep(wait_time)
                
                completion = await client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "developer", "content": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–∑—ã–≤—ã –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É .–í—ã–¥–µ–ª–∏ –≥–ª–∞–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã (—Ñ–∞–π–ª —Å 1 –∑–≤–µ–∑–¥–æ–π) –∏ –ø—Ä–∏–µ–º—É—â–µ—Å—Ç–≤–∞(—Ñ–∞–π–ª —Å 5 –∑–≤–µ–∑–¥–∞–º–∏)."},
                        {"role": "user", "content": prompt}
                    ],
                    timeout= 60,
                    max_tokens=1500,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
                    temperature=0.7
                )
                
                return completion.choices[0].message.content
                
            except Exception as e:
                error_msg = str(e)
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å –º–æ–¥–µ–ª—å—é {model}: {error_msg}")
                
                if "rate-limited" in error_msg or "429" in error_msg:
                    if attempt < max_retries - 1:
                        continue  # –ü—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑ —Å —Ç–æ–π –∂–µ –º–æ–¥–µ–ª—å—é
                    else:
                        continue  # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π –º–æ–¥–µ–ª–∏
                else:
                    continue  # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π –º–æ–¥–µ–ª–∏

async def create_analyze_file():
    text = await ai_generate_from_csv()
    with open(f'reviews_analyze.txt', 'w', encoding='utf-8') as f:
            f.write(text)